# Big-Data-Project---Hadoop-MapReduce
Un projet complet d√©montrant l'utilisation de Hadoop, HDFS et MapReduce pour le traitement de donn√©es √† grande √©chelle.
# PROJET BIG DATA - HADOOP & MAPREDUCE

## 1. Installation du Cluster Hadoop

### Pr√©requis
- Installer Docker

### √âtapes d'installation

1. T√©l√©charger l'image hadoop-spark-cluster :
   docker pull yassern1/hadoop-spark-jupyter:1.0.3

2. Cr√©ation d'un volume de partage :
   Pour mon cas : C:\Users\pc\Documents\hadoop_project

3. Cr√©ation des trois conteneurs :

   a. Cr√©er un r√©seau pour relier les conteneurs :
      docker network create --driver=bridge hadoop

   b. Cr√©er et lancer les trois conteneurs :

      - Conteneur 1 : hadoop-master
        docker run -itd -v C:\Users\pc\Documents\hadoop_project/:/shared_volume --net=hadoop -p 9870:9870 -p 8088:8088 -p 7077:7077 -p 19888:19888 --name hadoop-master --hostname hadoop-master yassern1/hadoop-spark-jupyter:1.0.3

      - Conteneur 2 : hadoop-slave1
        docker run -itd -p 8040:8042 --net=hadoop --name hadoop-slave1 --hostname hadoop-slave1 yassern1/hadoop-spark-jupyter:1.0.3

      - Conteneur 3 : hadoop-slave2
        docker run -itd -p 8041:8042 --net=hadoop --name hadoop-slave2 --hostname hadoop-slave2 yassern1/hadoop-spark-jupyter:1.0.3

4. Configuration initiale :

   a. Acc√©der au master :
      docker exec -it hadoop-master bash

   b. D√©marrer Hadoop et YARN :
      ./start-hadoop.sh

   c. Cr√©er les r√©pertoires HDFS :
      hadoop fs -mkdir -p /user/root
      hdfs dfs -mkdir input

5. Copier des fichiers vers HDFS :

   a. Placer les fichiers dans le dossier hadoop_project sur la machine locale
   b. Copier vers HDFS depuis le conteneur :
      hdfs dfs -put /shared_volume/datasets/fichier.txt input/


## 2. Programmation avec l'API HDFS

### Structure du projet
- Cr√©er un projet Maven nomm√© "BigData"
- Cr√©er le package : edu.ensias.bigdata.tp1

### Application 1 : HadoopFileStatus
- Cr√©er la classe HadoopFileStatus.java
- Extraire vers le JAR : C:\Users\pc\Documents\hadoop_project\HadoopFileStatus.jar
- Commande d'ex√©cution :
  hadoop jar /shared_volume/HadoopFileStatus.jar edu.ensias.bigdata.tp1.HadoopFileStatus /user/root/input purchases.txt nouveau_nom.txt

### Application 2 : HDFSInfo
- Cr√©er la classe HDFSInfo.java
- Extraire le JAR vers shared_volume
- Commande d'ex√©cution :
  hadoop jar /shared_volume/HDFSInfo.jar edu.ensias.bigdata.tp1.HDFSInfo /user/root/input/new.txt

### Application 3 : ReadHDFS
- Cr√©er la classe ReadHDFS.java
- Extraire le JAR vers shared_volume
- Commande d'ex√©cution :
  hadoop jar /shared_volume/ReadHDFS.jar edu.ensias.bigdata.tp1.ReadHDFS /user/root/input/purchases.txt

### Application 4 : HDFSWrite
- Cr√©er la classe HDFSWrite.java
- Extraire le JAR vers shared_volume
- Commande d'ex√©cution :
  hadoop jar /shared_volume/HDFSWrite.jar edu.ensias.bigdata.tp1.HDFSWrite /user/root/output/message.txt "dadiiii"


## 3. Programmation avec l'API MapReduce

### Objectif
Simuler l'exemple WordCount pour compter le nombre d'occurrences de chaque mot dans un fichier texte.

### Architecture du traitement
- Phase de Mapping : D√©coupe le texte en mots et g√©n√®re des paires (mot, 1)
- Phase de Reducing : Regroupe par mot et fait la somme des occurrences

### Impl√©mentation

1. Structure du projet :
   - Cr√©er le package : edu.ensias.hadoop.mapreducelab
   - Emplacement : src/main/java/edu/ensias/hadoop/

2. Classes √† cr√©er :

   a. TokenizerMapper (Mapper)
      - Prend chaque ligne de texte
      - Tokenise en mots
      - √âmet des paires (mot, 1)

   b. IntSumReducer (Reducer)
      - Agr√®ge les valeurs pour chaque cl√©
      - Calcule la somme des occurrences
      - √âmet des paires (mot, total)

   c. WordCount (Classe principale)
      - Configure et lance le job MapReduce
      - D√©finit les classes Mapper et Reducer
      - Sp√©cifie les chemins d'entr√©e/sortie

3. D√©ploiement et ex√©cution :

   a. Exporter le projet en JAR vers shared_volume local
   b. Dans le bash de Hadoop master, ex√©cuter :
      hadoop jar /shared_volume/WordCount.jar input/new.txt output2/resultat

### Notes importantes
- Le r√©pertoire de sortie ne doit pas exister avant l'ex√©cution
- Utiliser : hadoop fs -rm -r output2/resultat pour supprimer l'ancien r√©sultat
- V√©rifier les r√©sultats avec : hadoop fs -cat output2/resultat/part-r-00000


## 4. MapReduce avec Python

### Objectif
Impl√©menter l'exemple wordcount avec MapReduce en Python et l'utilitaire Hadoop Streaming.

### √âtapes d'ex√©cution

1. Pr√©paration des fichiers :
   - Cr√©er deux fichiers Python : mapper.py et reducer.py
   - Cr√©er un fichier alice.txt (contenant le texte √† analyser)
   - Placer ces fichiers dans le dossier /shared_volume/python/

2. Contenu des fichiers Python :

mapper.py
reducer.py

3. Ex√©cution dans le bash du master :

# Acc√©der au conteneur et v√©rifier les fichiers
cd /shared_volume/python
ls -la mapper.py reducer.py alice.txt

# Trouver le JAR Hadoop Streaming
find / -name "hadoop-streaming*.jar" 2>/dev/null
# R√©sultat attendu : /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.2.0.jar

# Tester les scripts Python localement
cat alice.txt | python3 mapper.py
cat alice.txt | python3 mapper.py | sort | python3 reducer.py

# Donner les permissions d'ex√©cution
chmod +x mapper.py reducer.py

# Copier le fichier vers HDFS
hadoop fs -put alice.txt input/

# Ex√©cuter le job MapReduce avec Hadoop Streaming
hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.2.0.jar \
    -files /shared_volume/python/mapper.py,/shared_volume/python/reducer.py \
    -mapper "python3 mapper.py" \
    -reducer "python3 reducer.py" \
    -input input/alice.txt \
    -output output_python_wordcount

4. V√©rification des r√©sultats :

# Lister les fichiers de sortie
hadoop fs -ls output_python_wordcount

# Afficher le r√©sultat complet
hadoop fs -cat output_python_wordcount/part-00000

# Afficher les premiers r√©sultats
hadoop fs -cat output_python_wordcount/part-00000 | head -20









========================================
TP APACHE KAFKA - GUIDE SIMPLE
========================================

OBJECTIFS DU TP :
- Installation d'Apache Kafka
- Premi√®re utilisation d'Apache Kafka
- Cr√©ation d'une application Kafka en Java
- Communication Producer/Consumer en temps r√©el

========================================
CONCEPTS FONDAMENTAUX
========================================

Apache Kafka :
- Syst√®me de messagerie distribu√© bas√© sur le pattern Publish/Subscribe
- Permet de publier et s'abonner √† des flux d'√©v√©nements
- Stocke les √©v√©nements de mani√®re durable
- Traite les flux d'√©v√©nements en temps r√©el

Zookeeper :
- Service centralis√© pour la coordination
- G√®re la synchronisation entre les n≈ìuds Kafka

========================================
DEMARRAGE DE L'ENVIRONNEMENT
========================================

1. D√©marrer les conteneurs :
   docker start hadoop-master hadoop-slave1 hadoop-slave2

2. Acc√©der au master :
   docker exec -it hadoop-master bash

3. D√©marrer Hadoop :
   ./start-hadoop.sh

4. D√©marrer Kafka et Zookeeper :
   ./start-kafka-zookeeper.sh

5. V√©rifier le d√©marrage :
   jps

========================================
CONFIGURATION KAFKA
========================================

Cr√©er un topic :
kafka-topics.sh --create --bootstrap-server localhost:9092 \
    --replication-factor 1 --partitions 1 --topic idf

Lister les topics :
kafka-topics.sh --list --bootstrap-server localhost:9092

Afficher les d√©tails du topic :
kafka-topics.sh --describe --topic idf --bootstrap-server localhost:9092

========================================
TEST AVEC KAFKA CLI
========================================

Terminal 1 - Producer (Console) :
kafka-console-producer.sh --bootstrap-server localhost:9092 --topic idf

Terminal 2 - Consumer (Console) :
kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic idf --from-beginning

========================================
APPLICATION JAVA KAFKA
========================================

Structure du projet :
kafka_lab/
‚îú‚îÄ‚îÄ pom.xml
‚îî‚îÄ‚îÄ src/main/java/edu/ensias/kafka/
    ‚îú‚îÄ‚îÄ EventProducer.java
    ‚îî‚îÄ‚îÄ EventConsumer.java

Compilation :
mvn clean package -DskipTests

JARs g√©n√©r√©s :
- target/producer.jar
- target/consumer.jar

Copier les JARs :
cp target/producer.jar /shared_volume/kafka/
cp target/consumer.jar /shared_volume/kafka/

========================================
EXECUTION DE L'APPLICATION
========================================

Terminal 1 - Lancer le Consumer :
java -jar /shared_volume/kafka/consumer.jar idf

Terminal 2 - Lancer le Producer :
java -jar /shared_volume/kafka/producer.jar idf

Taper des messages dans le Producer :
Message > Bonjour Kafka
Message > Ceci est un test
Message > exit

R√©sultat dans le Consumer :
>>> MESSAGE RE√áU <<<
Partition: 0 | Offset: 0
Cl√©: 1
Message: Bonjour Kafka
-----------------------------------

========================================
FLUX DE COMMUNICATION
========================================

Producer ‚Üí Topic (idf) ‚Üí Consumer

Producer :
- Interface interactive
- Accepte les messages saisis par l'utilisateur
- Envoie les messages √† Kafka
- Arr√™t avec "exit"

Consumer :
- √âcoute le topic en temps r√©el
- Affiche les messages re√ßus
- Arr√™t avec Ctrl+C

========================================
COMMANDES UTILES
========================================

jps
- Affiche les processus Java en cours

netstat -tulpn | grep 9092
- V√©rifie que Kafka √©coute sur le port 9092

mvn clean package -DskipTests
- Compile le projet Maven

========================================
DEPANNAGE
========================================

Erreur "Connection refused on port 9092" :
‚Üí Kafka n'est pas d√©marr√©. Lancez ./start-kafka-zookeeper.sh

Erreur "Topic not found" :
‚Üí Cr√©ez le topic avec kafka-topics.sh --create

Pas de messages re√ßus :
‚Üí V√©rifiez que le Producer a envoy√© des messages

Erreur de compilation Maven :
‚Üí V√©rifiez la syntaxe Java et les d√©pendances



PARTIE 2 : 


Description - Kafka Connect (Sink et Fichiers)
üìå Qu'est-ce que Kafka Connect ?
Kafka Connect est un framework qui permet de faire circuler les donn√©es entre Kafka et d'autres syst√®mes (fichiers, bases de donn√©es, APIs, etc.) sans √©crire de code.
Il utilise deux types de connecteurs :

Source Connector : Lit les donn√©es d'une source externe et les envoie √† Kafka
Sink Connector : Re√ßoit les donn√©es de Kafka et les √©crit vers une destination externe


========================================
KAFKA CONNECT - GUIDE COMPLET
========================================

FICHIERS DE CONFIGURATION EXISTANTS :

connect-file-source.properties :
  - file=test.txt
  - topic=connect-test

connect-file-sink.properties :
  - file=test.sink.txt
  - topics=connect-test

========================================
√âTAPE 1 : AJOUTER LE PLUGIN PATH
========================================

Commande :
echo "plugin.path=/usr/local/kafka/libs/" >> $KAFKA_HOME/config/connect-standalone.properties

V√©rifier :
tail $KAFKA_HOME/config/connect-standalone.properties

========================================
√âTAPE 2 : CR√âER LE TOPIC KAFKA
========================================

Commande :
kafka-topics.sh --create --bootstrap-server localhost:9092 \
    --topic connect-test --partitions 1 --replication-factor 1

V√©rifier :
kafka-topics.sh --list --bootstrap-server localhost:9092

========================================
√âTAPE 3 : CR√âER LE FICHIER SOURCE
========================================

Aller dans le dossier Kafka :
cd $KAFKA_HOME

Cr√©er le fichier test.txt avec des donn√©es :
echo "Bonjour Kafka" > test.txt
echo "Bienvenue dans le monde du streaming" >> test.txt

V√©rifier :
cat test.txt

R√©sultat attendu :
Bonjour Kafka
Bienvenue dans le monde du streaming

========================================
√âTAPE 4 : D√âMARRER KAFKA CONNECT
========================================

Commande (dans le dossier $KAFKA_HOME) :
cd $KAFKA_HOME

./bin/connect-standalone.sh \
    config/connect-standalone.properties \
    config/connect-file-source.properties \
    config/connect-file-sink.properties

Vous devriez voir les logs :
[INFO] Starting FileStreamSource with tasks.max=1
[INFO] Starting FileStreamSink with tasks.max=1

Ne fermez pas ce terminal !

========================================
√âTAPE 5 : V√âRIFIER LES R√âSULTATS
========================================

Ouvrir un NOUVEAU terminal et ex√©cuter :

cd $KAFKA_HOME
cat test.sink.txt

R√©sultat attendu :
Bonjour Kafka
Bienvenue dans le monde du streaming

========================================
√âTAPE 6 : TESTER LE PIPELINE EN TEMPS R√âEL
========================================

Dans le nouveau terminal, ajouter une ligne au fichier source :
echo "Exercice Kafka Connect simple" >> test.txt

V√©rifier imm√©diatement que la ligne s'est synchronis√©e :
cat test.sink.txt

R√©sultat attendu :
Bonjour Kafka
Bienvenue dans le monde du streaming
Exercice Kafka Connect simple

========================================
EMPLACEMENTS DES FICHIERS
========================================

Tous les fichiers se trouvent dans $KAFKA_HOME :

$KAFKA_HOME/
‚îú‚îÄ‚îÄ test.txt                    ‚Üê Fichier source (entr√©e)
‚îú‚îÄ‚îÄ test.sink.txt               ‚Üê Fichier destination (sortie)
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ connect-standalone.properties
‚îÇ   ‚îú‚îÄ‚îÄ connect-file-source.properties
‚îÇ   ‚îî‚îÄ‚îÄ connect-file-sink.properties
‚îî‚îÄ‚îÄ bin/
    ‚îî‚îÄ‚îÄ connect-standalone.sh

========================================
FLUX DE COMMUNICATION
========================================

test.txt (source)
   ‚Üì
FileStreamSource lit ligne par ligne
   ‚Üì
Envoie au topic : connect-test
   ‚Üì
FileStreamSink re√ßoit du topic
   ‚Üì
test.sink.txt (destination)

========





========================================
KAFKA STREAMS - WORD COUNT APPLICATION
========================================

OBJECTIF :
D√©velopper une application Kafka Streams qui :
1. Lit des phrases depuis un topic Kafka (input-topic)
2. Compte la fr√©quence des mots
3. Envoie les r√©sultats vers un autre topic (output-topic)

========================================
CONCEPT DE BASE
========================================

Kafka Streams est un framework pour traiter les flux de donn√©es en temps r√©el.

Flux de traitement :
Input Topic (phrases brutes)
    ‚Üì
WordCountApp (traitement)
    ‚Üì
Output Topic (mots + compteurs)

Exemple :
Entr√©e : "Bonjour le monde, Bonjour √† tous"
Sortie : 
  bonjour ‚Üí 2
  le ‚Üí 1
  monde ‚Üí 1
  √† ‚Üí 1
  tous ‚Üí 1

========================================
√âTAPE 1 : METTRE √Ä JOUR LE POM.XML
========================================

VOIR LE PROJET
========================================
√âTAPE 2 : CR√âER LA CLASSE WORDCOUNTAPP
========================================

========================================
√âTAPE 3 : COMPILER LE PROJET
========================================

Commande :
cd kafka_lab
mvn clean package -DskipTests

R√©sultat :
Trois JARs sont g√©n√©r√©s dans target/ :
- producer.jar
- consumer.jar
- wordcount-app.jar ‚Üê C'est celui-ci qu'on va utiliser

V√©rifier :
ls -lh target/*.jar

========================================
√âTAPE 4 : COPIER LE JAR
========================================

Copier sur Windows :
copy target\wordcount-app.jar C:\Users\pc\Documents\hadoop_project\kafka\

Ou sur le serveur Hadoop :
cp target/wordcount-app.jar /shared_volume/kafka/

========================================
√âTAPE 5 : CR√âER LES TOPICS KAFKA
========================================

Topic d'entr√©e (input-topic) :

kafka-topics.sh --create --bootstrap-server localhost:9092 \
    --topic input-topic \
    --partitions 1 \
    --replication-factor 1

Topic de sortie (output-topic) :

kafka-topics.sh --create --bootstrap-server localhost:9092 \
    --topic output-topic \
    --partitions 1 \
    --replication-factor 1

V√©rifier les topics :

kafka-topics.sh --list --bootstrap-server localhost:9092

R√©sultat attendu :
input-topic
output-topic

========================================
√âTAPE 6 : D√âMARRER L'APPLICATION
========================================

Commande :
java -jar /shared_volume/kafka/wordcount-app.jar input-topic output-topic

R√©sultat attendu :
========================================
Kafka Streams Word Count Application
========================================
Input Topic: input-topic
Output Topic: output-topic
========================================
Application d√©marr√©e. En attente de messages...

IMPORTANT : Ne fermez pas ce terminal !
L'application est en cours d'ex√©cution et attend des messages.

========================================
√âTAPE 7 : ENVOYER DES DONN√âES (PRODUCER)
========================================

Ouvrir un NOUVEAU terminal et lancer le producer :

kafka-console-producer.sh --broker-list localhost:9092 --topic input-topic

Taper des phrases (une par ligne) :

Bonjour le monde
Kafka est formidable
Streaming de donn√©es en temps r√©el
Bonjour √† tous

Appuyer sur Ctrl+C pour arr√™ter le producer

========================================
√âTAPE 8 : LIRE LES R√âSULTATS (CONSUMER)
========================================

Ouvrir un AUTRE terminal et lancer le consumer :

kafka-console-consumer.sh --topic output-topic \
    --from-beginning \
    --bootstrap-server localhost:9092 \
    --property print.key=true

R√©sultat attendu :
bonjour	Mot: , Nombre: 2
le	Mot: , Nombre: 1
monde	Mot: , Nombre: 1
kafka	Mot: , Nombre: 1
est	Mot: , Nombre: 1
formidable	Mot: , Nombre: 1
streaming	Mot: , Nombre: 1
de	Mot: , Nombre: 1
donn√©es	Mot: , Nombre: 1
en	Mot: , Nombre: 1
temps	Mot: , Nombre: 1
r√©el	Mot: , Nombre: 1
√†	Mot: , Nombre: 1
tous	Mot: , Nombre: 1

========================================
ARCHITECTURE KAFKA STREAMS
========================================

Topologie cr√©√©e dans l'application :

Source (input-topic)
    ‚Üì
flatMapValues (diviser chaque valeur en plusieurs)
    ‚Üì
filter (supprimer les valeurs vides)
    ‚Üì
groupBy (regrouper par mot)
    ‚Üì
count (compter les occurrences)
    ‚Üì
toStream (convertir la table en stream)
    ‚Üì
mapValues (transformer le compteur en string)
    ‚Üì
Sink (output-topic)


